### 19장 
1. 파티셔닝과 효율적인 바이너리 포맷을 사용해 가능한 작은 데이터를 읽습니다
2. 충분한 병렬성을 보장하고 파티셔닝을 사용해 데이터 치우침 현상을 방지합니다 
3. 최적화된 코드를 제공하는 구조적 API 를 최대한 활용합니다

→ 모니터링 도구로 가장 오래 실행되는 스테이지를 찾아 그 문제에 집중해 성능 최적화를 진행합니다 

## 19.1 속성값을 설정하하거나 런타임 환경을 변경하는 간접적인 방법

**19.1.1 설계 방안**

 A.언어의 선택

- 용도에 따라 다름: ETL 부터 머신러닝까지 수행한다면 파이썬이나 R 을 통해 스파크와 각 언어가 제공하는 기능을 모두 누릴 수 있음 (또 이런 경우 구조적 API 를 사용하면 됨
- 그러나 구조적 API 를 사용할 수 없는 사용자 정의 트랜스포메이션이 필요하다면 (RDD 를 직접 만지거나 , UDF 를 사용하는 경우) 자바나 스칼라를 이용해 해당 부분만 변경

 B. DataFrame vs SQL vs Dataset vs RDD 

- DataFrame 과 SQL 과 Dataset 의 성능은 동일하며 이는 모두 RDD 로 컴파일 됨
- 기본적으로 성능 개선을 위해서는 이미 구조화된 API 인 DataFrame 이나 SQL 을 사용한다 (RDD 를 직접 만지는 것보다 이미 최적화된 엔진을 사용하여 더 나은 RDD 를 만드는 게 더 낫고 더 쉬운 방법이다)
- 파이썬이나 R 을 통해 UDF 를 정의하면 성능저하가 발생함. 따라서 자바나 스칼라로 UDF 를 정의하던지 아예 피해야 한다… (기본적으로 모든게 자바 기반이라, DataFrame 이나 Spark SQL 은 JVM 에서 바로 동작할 수 있음. 그런데 파이썬 UDF 를 작성하면, 파이썬을 이해할 수 있는 머신으로 데이터와 함수를 한꺼번에 던지게 되고,,, 그러면 당연히 오래걸림)
- 또한 RDD 를 직접 만져야 한다면 스칼라나 자바를 사용하고, 스칼라나 자바를 사용할 수 없다면 RDD 사용영역을 최소한으로 해야 함. 파이썬에서 RDD 코드를 실행하면 파이썬 프로세스를 오가면서 데이터를 직렬화해야 해 좋지 않음

**19.1.2 RDD 객체 직렬화**

*직렬화란?? Serialization 으로 객체를 저장할 수 있는 파일 형태로 변환하는 것을 말함 (Python 에서 pickle 을 저장한다거나,,, powerpoint 같은 파일도 프로그램 없이 열게 되면 그 자체는 직렬화된 상태로 저장되어 있음)*

- RDDTransformation 을 할 때 직접 정의한 데이터 타입을 직렬화하려면 Java보다 Kyro 직렬화를 사용하자 (다만 클래스를 spark.kryo.classesToRegister 속성값에 지정해 등록해야 함)

**19.1.3 클러스터 설정**

- 머신 자체의 성능을 모니터링하면서 클러스터의 자원 공유, 잡의 스케줄링 등 설정을 최적화할 수 있음 (16장 후반부와 17장의 일부 설정을 참조하자)
- 단일 클러스터에서 여러개의 애플리케이션이 실행될 때, 워크로드에 따라 동적으로 자원을 조절하는 “동적 할당” 이 도움될 수 있음.  즉 자원을 적게 사용하는 애플리케이션은 사용하지 않는 자원을 클러스터에 반환하여 더 큰 자원을 필요로 하는 다른 애플리케이션이 사용하도록 할 수 있음

**19.1.4 스케줄링**

- Spark.scheduler.mode = FAIR 또는 —max-executor-cores 인수를 사용 (이렇게 하면 한 개의 자원이 클러스터의 자원을 다 사용하는 것은 못하게 할 수 있음)

**19.1.5 보관용 데이터 (Archived Data)**

- 자주 사용하는 데이터셋은 효율적으로 읽을 수 있도록 저장되어야 하고, 이를 위해 저장소와 데이터 포맷을 선택해야 함.
- 파일기반 장기 데이터 저장소는 다양한 파일을 저장할 수 있는데, 이 때 best practice 를 따라라 ^^
    - 자주 읽는 데이터는 바이너리 형태로 저장하는 것을 권장하며 그중 Apache Parquet 같은 구조적 api 가 좋음. (Csv 는 보기엔 구조화되어 있는 것 같지만 파싱 속도가 아주 느리고 예외상황도 잘 발생함)
- 분할 가능한 파일 포맷은 여러 태스크가 접근하더라도, 같은 파일을 동시에 읽을 수 있어 효율적이다. (JSON 은 대표적으로 분할 불가능한 포맷임)
    - 압축 포맷에서 ZIP 이나 TAR 는 분할이 안되 병렬 처리가 안됨. (10개 코어가 있어도 하나만 사용함). 병렬처리가 가능한 상태에서는 gzip, bzip2, lz4를 통해 압축한 파일을 사용하자.
- 테이블 파티셔닝
    - 날짜 같은 키 기준으로 개별 디렉터리에 파일을 저장함. 다만 너무 작은 단위로 분할하면 전체 파일 목록 (메타) 를 읽을 때 오버헤드가 발생해 좋지 않다
- 버켓팅
    - 파티셔닝과 비슷한 개념. 다만 디렉터리로 파일을 분산시키는 것은 아니며 파티셔닝과 함께 쓰일 수도, 없이 쓰일 수도 있다. 키를 기반으로 하지 않고 데이터 사이즈를 기반으로 하기 때문에 치우침 (skew) 없이 균등하게 분산시킬 수 있어 성능과 안정성이 향상됨. (조인컬럼 기준으로 데이터를 분할해두고 조인을 한다든가)
- 파티셔닝이나 버켓팅을 할 때는 파일 수나 저장하려는 파일 크기도 고려해야 함. one partition = one block (데이터를 입출력하는 단위) 이라고 생각했을 때,,, 5MB 짜리로 30개 파일로 쪼갰다면, 30개 블록을 사용하게 됨.
    - 그래서 밸런스를 (최소 수십 MB로 파일 사이즈를 맞추는 게 좋음) 찾아야 한다…
    - 많은 수의 작은 파일이 있으면 네트워크와 스케줄링 부하가 증가함.
    - 반대로 적은 수의 대용량 파일이 있다면 스케줄링 문제는 없지만, 태스크 수행 시간이 길어짐 (다만 입력 파일 수보다 더 많은 태스크 수를 설정하면 병렬성이 높아짐)
- 데이터 지역성 (data locality) 은 기본적으로 데이터 블록이 네트워크를 통해 교환될 수 있기 때문에, 네트워크에서 가까운 노드에서 동작할 수 있도록 지정하는 것을 말함.
    - 입력 데이터 블록과 최대한 가까운 노드에 태스크를 할당하거나, 또는 특정 데이터를 가진 노드에서 동작하도록 하려면 몇가지 설정을 활용해 지역성 수준을 조정할 수 있음
- 통계 수집
    - 테이블 수준 또는 컬럼 수준의 통계 수집 (ANALYZE TABLE table_name COMPUTE STATISTICS (for COLUMNS col1, col2, …)
    - 비용 기반 옵티마이저에서 사용할 수 있는 데이터 컬럼 관련된 정보를 제공함으로써, 조인/집계/필터링/브로드캐스트 등의 상황에서 효율적인 쿼리 실행 계획을 만들 수 있음

**19.1.6 셔플 설정**

- 기본값만으로도 충분하다: 다만 스파크의 외부 셔플 서비스를 설정하면(???) 머신에서 실행되는 익스큐터가 바쁜 상황에서도 원격 머신에서 셔플 데이터를 읽을 수 있음 (그러나 코드가 복잡해지고 유지가 어려워 운영에는 적합하지 않음)
- Kryo 직렬화를 사용하면 셔플 성능에 큰 영향을 미침.
- 파티션 하나당 최소 수십 메가 데이터를 포함하도록 하는 게 최적 (파티션 수가 너무 적으면 치우침 발생하고, 파티션 수가 너무 많으면 태스크를 많이 실행해야 해 부하 발생)

**19.1.7 메모리 부족과 가비지 컬렉션**

- 메모리 부족의 원인은 1) 메모리 사용량이 너무 많거나 2) 가비지 컬렉션이 자주 수행되는 것 그리고 3) JVM 내 객체가 너무 많이 생성되어 더이상 사용하지 않는 객체를 (가비지 컬렉션을 통해) 정리하면서 느려지는 경우.
    - 3번째는 구조적 API 를 사용해 JVM 객체를 생성하지 않게 함으로서 줄일 수 있다.
- 가비지 컬렉션
    - Java Heap 은 Young and Old 영역으로 나눠지고, Young 은 다시 Eden, Survivor1, Survivor2 로 나눠짐
    - Eden 이 가득차면, minor garbage collection 을 통해 Eden 의 살아남은 (surviving) 객체와 Survivor 1을 Survivor 2로 이동 → Survivor 를 교체 → Survivor2가 가득차면 Old 로 옮김 → Old가 가득 차면 Full gargabe collection 수행 (전체 Heap 을 추적해 참조 정보가 없는 것을 제거하고 나머지는 빈곳으로 옮김: 가장 느림)
    - 수명이 긴 캐시 데이터셋을 Old 에 저장하고, Young은 수명이 짧은 모든 객체를 보관할 수 있게 충분한 공간을 유지하여 Full Garbage collection 을 피하자
    - 가비지 컬렉션의 발생 빈도와 소요시간을 집계해 보고 (속성값 설정을 통해 워커의 로그에 가비지 컬렉센이 발생할 때마다 메세지 출력 하도록 함)
        - 태스크가 완료되기 전에 full garbage collection 이 자주 발생하면 캐싱에 사용되는 메모리양을 줄여 태스크를 처리하기 위한 메모리를 확보
        - 마이너는 자주 발생하나 메이저가 자주 발생하지 않으면 Eden 영역에 메모리를 더 할당 (HDFS에서 데이터를 읽으면 읽어야할 데이터 블록 크기로 메모리양을 추정해 Eden 에 할당)
        - G1GC 가비지 컬렉터는 가비지 컬렉션이 병목 현상을 일으키며 각 영역의 크기를 늘려도 부하가 발생할 때 성능을 높일 수 있다

## 19.2 개별 스파크 잡, 스테이지, 태스크의 성능 튜닝을 시도하거나 코드 설계를 변경하는 직접적인 방법 

**19.2.1 병렬화**

- Spark.default.parallelism
- Spark.sql.shuffle.partitions

**19.2.2 향상된 필터링**

- 최종 결과와 무관한 데이터는 최대한 이른 시점부터 읽지 않음
- 파티셔닝과 버켓팅을 활용

**19.2.3 파티션 재분배와 병합**

- 파티션 재분배는 셔플을 수반해 비효율적일 수 있으나 (그러므로 가능한 한 적은 양의 데이터를 셔플하자) 클러스터 전체에 데이터를 균등하게 분배시켜 전체 실행은 최적화하고 병렬성을 높일 수 있음
- 셔플 대신 동일 노드의 파티션을 하나로 합치는 coalesce 메써드를 실행해 전체적으로 파티션 수를 줄여줄 수 있음
    - Repartition 은 네트워크를 통해 셔플을 수반함
- 사용자 정의 파티셔닝: RDD 단계에서 파티셔닝하는 방법으로 보다 정밀하게 데이터 체계를 제어할 수 있음 (드물게 사용되지만 최적화 과정에서 생각해볼 수 있다)

**19.2.4 사용자 정의 함수 (UDF)**

- UDF 사용을 최대한 피하고 구조적 API를 최대한 활용
    - 스파크는 UDF에서 대량의 데이터를 한번에 처리하는 기능을 개발 중 (Vectorized UDF 같은,,,)

**19.2.5 임시 데이터 저장소 (Caching)**

- 같은 데이터셋을 재사용하면 매번 원시 데이터를 사용하는 것이 아니라 캐싱을 활용 (늘 유용하진 않음)
    - Interactive shell 이나 stand-alone application 에서 재사용하려 할 때는 유용함
    - 캐싱은 지연연산인데, RDD 와 구조적 API 의 캐싱 수행 방식이 다름
    - RDD 에서의 caching 은 물리적 데이터 (비트 값)을 캐시에 저장하고 RDD 참조를 통해 데이터를 반환
    - 구조적 API는 물리적 실행 계획을 기반으로 이뤄져 객체 참조가 아니라, 물리적 실행 계획을 참조함 (따라서 원시 데이터를 읽으려 시도했지만 누군가가 캐싱해놓은 데이터를 읽으면 혼란이 발생할 수 있음???)
    - 저장소 레벨의 옵션들
    - MEMORY_ONLY: RDD 를 직렬화되지 않은 자바 객체로 JVM 에 저장. JVM에 할당된 메모리보다 크면 메모리 크기를 벗어나는 파티션은 캐싱되지 않으며 필요할 때마다 재연산됨
    - MEMORY_AND_DISK: 메모리 크기를 벗어나는 파티션을 디스크에 저장
    - MEMORY_ONLY_SER: RDD를 직렬화된 자바 객체로 JVM에 저장 (직렬화하기 때문에 효율적이나 데이터를 읽을 때 CPU 를 더 많이 사용함)
    - DISK_ONLY: MEMORY_ONLY_SER 와 유사하지만 메모리 크기를 벗어나는 파티션은 디스크에 기록
    - MEMORY_ONLY_2:
    - MeMORY_AND_DISK_2
    - OFF_HEAP

**19.2.6 조인**

- 동등 조인을 우선적으로 사용하되 조인 순서를 변경해봄
- 브로드캐스트 조인 힌트를 통해 쿼리 실행 계획을 조인
- Cartesian join 이나 outer join 은 피하고 다양한 필터링을 먼저 활용해 봄
- Table statistics 이나 bucketing 을 사용하여 셔플 양이 많아지는 것을 방지

**19.2.7 집계**

- 데이터를 필터링 한 뒤에 집계하고 RDD를 사용하는 것이 도움이 될 수 있다 (대신 reduceByKey 를 사용)

**19.2.8 브로드캐스트 변수**

- 브로드캐스트 조인과 변수를 활용 (예: 다수의 UDF 에서 큰 데이터 조각을 사용하면, 데이터 재전송을 피하기 위해 데이터 조각을 UDF가 있는 개별 노드에 읽기 전용 복사본으로 저장
